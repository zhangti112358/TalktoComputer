# 人机交互可以更加自然且高效

人和计算机交互是从“二进制数据”到“命令行”再到“图形界面”。随着计算机对信息处理能力的提升，人机交互的趋势有：

1. 交互的信息种类增加，信息密度更大。
2. 交互方式更自然。（用眼看，手触摸）

现在的AI技术提升了对语言/图像的理解/生成能力。因此可以把图形界面交互，和语音这个人类天生，且信息密度很大的交互做的更好。

# 需要解决的问题
以“更好的人机交互”为目标，还有很多问题需要解决，可以分3层：

1. 交互方式
2. 需求理解
3. 程序执行

现在一些有趣的产品：

1. 音频眼镜（以及带相机的眼镜）。在实时语音交互和获取人的视觉这两点很有优势。为了佩戴舒适（40g内），拍照和视频的续航很短。另外我感觉现在能语音控制的功能很少，交互上的优势还没发挥出来。
2. Anthropic的MCP。看了它的示例和代码，感觉是Function call的扩大版。思路还是描述现有程序，给模型判断是否要调用。扩大的部分是支持文件或数据库等资源（Resource），给用户提供prompt模版等。同时定义了一套传递数据的模版（使用JSON-RPC格式）。还有个感觉是开发MCP的server只是个体力活，真正重要的是模型侧，即怎么理解人的需求并正确执行。
3. 智谱的glm-pc。思路是把需求分解成一系列GUI操作，通过屏幕录制和模拟键鼠操作执行。使用感受是它对GUI图像的理解很好，超过了我用之前的预期，不过判断需求和执行准确性还不够好。另外主要问题是“模拟人手点击”这样交互很别扭。

# 具体功能

如果类比GUI和IPhone，语音交互对应的“矩形圆角，双指缩放，惯性滑动”是什么呢？


